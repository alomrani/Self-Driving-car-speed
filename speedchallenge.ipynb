{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speedchallenge.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM+1cFtZhH7Seh4xTm2YFlX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alomrani/Self-Driving-car-speed/blob/master/speedchallenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXD0ccliZ1j1",
        "colab_type": "code",
        "outputId": "28976c1d-7ee2-4397-8d54-2c135a5b5697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import collections\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import pylab\n",
        "use_colab = True\n",
        "if use_colab:\n",
        "  from google.colab import drive\n",
        "import tensorflow as tf\n",
        "TINY = 1e-30\n",
        "EPS = 1e-4\n",
        "nax = np.newaxis\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import random\n",
        "import cv2\n",
        "import csv\n",
        "from skimage import color\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.init import kaiming_normal_, constant_\n",
        "# from .util import conv, predict_flow, deconv, crop_like\n",
        "# Hyper-parameters \n",
        "input_size = 4096   # 784\n",
        "num_classes = 10\n",
        "num_epochs = 35\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "momentum = 0.8\n",
        "if use_colab:\n",
        "  drive_name = '/content/drive'\n",
        "  drive.mount(drive_name)\n",
        "  drive_413_A1_folder = 'comma_ai_speedchallenge'\n",
        "  drive_location = drive_name + '/My Drive/' + drive_413_A1_folder  # Change this to where your files are located\n",
        "else:\n",
        "  # set the drive_location variable to whereever the extracted contents are.\n",
        "  drive_location = ''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsK4YuDKyLwH",
        "colab_type": "code",
        "outputId": "e8b64eae-9a88-45bb-df1c-87e5f2c0d51f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "try:\n",
        "    from spatial_correlation_sampler import spatial_correlation_sample\n",
        "except ImportError as e:\n",
        "    import warnings\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.filterwarnings(\"default\", category=ImportWarning)\n",
        "        warnings.warn(\"failed to load custom correlation module\"\n",
        "                      \"which is needed for FlowNetC\", ImportWarning)\n",
        "\n",
        "\n",
        "def conv(batchNorm, in_planes, out_planes, kernel_size=3, stride=1):\n",
        "    if batchNorm:\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=(kernel_size-1)//2, bias=False),\n",
        "            nn.BatchNorm2d(out_planes),\n",
        "            nn.LeakyReLU(0.1,inplace=True)\n",
        "        )\n",
        "    else:\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=(kernel_size-1)//2, bias=True),\n",
        "            nn.LeakyReLU(0.1,inplace=True)\n",
        "        )\n",
        "\n",
        "\n",
        "def predict_flow(in_planes):\n",
        "    return nn.Conv2d(in_planes,2,kernel_size=3,stride=1,padding=1,bias=False)\n",
        "\n",
        "\n",
        "def deconv(in_planes, out_planes):\n",
        "    return nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_planes, out_planes, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "        nn.LeakyReLU(0.1,inplace=True)\n",
        "    )\n",
        "\n",
        "\n",
        "def correlate(input1, input2):\n",
        "    out_corr = spatial_correlation_sample(input1,\n",
        "                                          input2,\n",
        "                                          kernel_size=1,\n",
        "                                          patch_size=21,\n",
        "                                          stride=1,\n",
        "                                          padding=0,\n",
        "                                          dilation_patch=2)\n",
        "    # collate dimensions 1 and 2 in order to be treated as a\n",
        "    # regular 4D tensor\n",
        "    b, ph, pw, h, w = out_corr.size()\n",
        "    out_corr = out_corr.view(b, ph * pw, h, w)/input1.size(1)\n",
        "    return F.leaky_relu_(out_corr, 0.1)\n",
        "\n",
        "\n",
        "def crop_like(input, target):\n",
        "    if input.size()[2:] == target.size()[2:]:\n",
        "        return input\n",
        "    else:\n",
        "        return input[:, :, :target.size(2), :target.size(3)]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: ImportWarning: failed to load custom correlation modulewhich is needed for FlowNetC\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcEHw0p5CRJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "import torch\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, save_path, filename='checkpoint.pth.tar'):\n",
        "    torch.save(state, os.path.join(save_path,filename))\n",
        "    if is_best:\n",
        "        shutil.copyfile(os.path.join(save_path,filename), os.path.join(save_path,'model_best.pth.tar'))\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '{:.3f} ({:.3f})'.format(self.val, self.avg)\n",
        "\n",
        "\n",
        "def flow2rgb(flow_map, max_value):\n",
        "    flow_map_np = flow_map.detach().cpu().numpy()\n",
        "    _, h, w = flow_map_np.shape\n",
        "    flow_map_np[:,(flow_map_np[0] == 0) & (flow_map_np[1] == 0)] = float('nan')\n",
        "    rgb_map = np.ones((3,h,w)).astype(np.float32)\n",
        "    if max_value is not None:\n",
        "        normalized_flow_map = flow_map_np / max_value\n",
        "    else:\n",
        "        normalized_flow_map = flow_map_np / (np.abs(flow_map_np).max())\n",
        "    rgb_map[0] += normalized_flow_map[0]\n",
        "    rgb_map[1] -= 0.5*(normalized_flow_map[0] + normalized_flow_map[1])\n",
        "    rgb_map[2] += normalized_flow_map[1]\n",
        "    return rgb_map.clip(0,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdEwKxX2Z3yN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def exctract_frames():\n",
        "  cap = cv2.VideoCapture(\"speedchallenge/data/train.mp4\")\n",
        "\n",
        "  i = 0\n",
        "  # with open(drive_location + \"/speedchallenge/data/dataX.csv\", \"a\") as f:\n",
        "    # writer = csv.writer(f)\n",
        "  while(cap.isOpened()):\n",
        "      ret, frame = cap.read()\n",
        "      if ret == False:\n",
        "          break\n",
        "      frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "      # print(1)\n",
        "      # writer.writerow(frame.flatten())\n",
        "      cv2.imwrite('speedchallenge/data/trainFrames/'+str(i)+'.jpg',frame)\n",
        "      i+=1\n",
        "\n",
        "  cap.release()\n",
        "  cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suiByj48rBGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_speed = []\n",
        "f = open(\"speedchallenge/data/train.txt\", \"r\")\n",
        "for s in f:\n",
        "  train_speed.append(float(s.strip()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmB3_MebwlZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataset_constructor(train_speed):\n",
        "    meta_dict = {}\n",
        "    for idx, speed in enumerate(train_speed):\n",
        "        img_path = 'speedchallenge/data/trainFrames/'+str(idx)+'.jpg'\n",
        "        meta_dict[idx] = [img_path, idx, speed]\n",
        "    meta_df = pd.DataFrame.from_dict(meta_dict, orient='index')\n",
        "    meta_df.columns = ['image_path', 'image_index', 'speed']\n",
        "    meta_df.to_csv('speedchallenge/data/train_meta.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWdXFi1hpJo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def pre_proccess(frame):\n",
        "#   frame = frame[:,80:370,:]\n",
        "#   frame = cv2.resize(frame, (220, 66), interpolation = cv2.INTER_AREA)\n",
        "#   return frame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpsI-nzSZ6j4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_constructor(train_speed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URUPIg20jIwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnVH3evArdo7",
        "colab_type": "code",
        "outputId": "b30b33e5-7e14-4e2e-c6c8-3d42b975f949",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_meta = pd.read_csv('speedchallenge/data/train_meta.csv')\n",
        "train_meta.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>image_index</th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>speedchallenge/data/trainFrames/0.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>28.105569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>speedchallenge/data/trainFrames/1.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>28.105569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>speedchallenge/data/trainFrames/2.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>28.106527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>speedchallenge/data/trainFrames/3.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>28.130404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>speedchallenge/data/trainFrames/4.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>28.109243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              image_path  image_index      speed\n",
              "0  speedchallenge/data/trainFrames/0.jpg            0  28.105569\n",
              "1  speedchallenge/data/trainFrames/1.jpg            1  28.105569\n",
              "2  speedchallenge/data/trainFrames/2.jpg            2  28.106527\n",
              "3  speedchallenge/data/trainFrames/3.jpg            3  28.130404\n",
              "4  speedchallenge/data/trainFrames/4.jpg            4  28.109243"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEPLFdEtzU_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_valid_split(dframe):\n",
        "    train_data = pd.DataFrame()\n",
        "    valid_data = pd.DataFrame()\n",
        "    for i in range(len(dframe) - 1):\n",
        "        idx1 = np.random.randint(len(dframe) - 1)\n",
        "        idx2 = idx1 + 1\n",
        "         \n",
        "        row1 = dframe.iloc[[idx1]].reset_index()\n",
        "        row2 = dframe.iloc[[idx2]].reset_index()\n",
        "        \n",
        "        randInt = np.random.randint(9)\n",
        "        if 0 <= randInt <= 1:\n",
        "            valid_frames = [valid_data, row1, row2]\n",
        "            valid_data = pd.concat(valid_frames, axis = 0, join = 'outer', ignore_index=False)\n",
        "        if randInt >= 2:\n",
        "            train_frames = [train_data, row1, row2]\n",
        "            train_data = pd.concat(train_frames, axis = 0, join = 'outer', ignore_index=False)\n",
        "    return train_data, valid_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTP_oSDh6pKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, val_data = train_valid_split(train_meta)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-A9QM97jD7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "from imageio import imread, imwrite\n",
        "class ArrayToTensor(object):\n",
        "    \"\"\"Converts a numpy.ndarray (H x W x C) to a torch.FloatTensor of shape (C x H x W).\"\"\"\n",
        "\n",
        "    def __call__(self, array):\n",
        "        assert(isinstance(array, np.ndarray))\n",
        "        array = np.transpose(array, (2, 0, 1))\n",
        "        # handle numpy array\n",
        "        tensor = torch.from_numpy(array)\n",
        "        # put it from HWC to CHW format\n",
        "        return tensor.float()\n",
        "\n",
        "input_transform = transforms.Compose([\n",
        "        ArrayToTensor(),\n",
        "        transforms.Normalize(mean=[0,0,0], std=[255,255,255]),\n",
        "        transforms.Normalize(mean=[0.411,0.432,0.45], std=[1,1,1])\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAMK-o7y6zKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_image_from_path(image_path, speed):\n",
        "    img = input_transform(cv2.imread(image_path))\n",
        "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = img[:,80:370,:]\n",
        "    return img, speed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aWwQETMw4Sy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "def generate_training_data(data, model,batch_size = 32):\n",
        "    image_batch = np.zeros((batch_size, 66, 220, 3)) # nvidia input params\n",
        "    label_batch = np.zeros((batch_size))\n",
        "    while True:\n",
        "        for i in range(batch_size):\n",
        "            # generate a random index with a uniform random distribution from 1 to len - 1\n",
        "            idx = np.random.randint(1, len(data) - 1)\n",
        "            \n",
        "            # Generate a random bright factor to apply to both images\n",
        "            bright_factor = 0.2 + np.random.uniform()\n",
        "            \n",
        "            row_now = data.iloc[[idx]].reset_index()\n",
        "            row_prev = data.iloc[[idx - 1]].reset_index()\n",
        "            row_next = data.iloc[[idx + 1]].reset_index()\n",
        "            \n",
        "            # Find the 3 respective times to determine frame order (current -> next)\n",
        "            \n",
        "            time_now = row_now['image_index'].values[0]\n",
        "            time_prev = row_prev['image_index'].values[0]\n",
        "            time_next = row_next['image_index'].values[0]\n",
        "            \n",
        "            if abs(time_now - time_prev) == 1 and time_now > time_prev:\n",
        "                row1 = row_prev\n",
        "                row2 = row_now\n",
        "                \n",
        "            elif abs(time_next - time_now) == 1 and time_next > time_now:\n",
        "                row1 = row_now\n",
        "                row2 = row_next\n",
        "            else:\n",
        "                print('Error generating row')            \n",
        "            \n",
        "            x1, y1 = preprocess_image_from_path(row1['image_path'].values[0],\n",
        "                                                row1['speed'].values[0]\n",
        "                                                )\n",
        "            \n",
        "            # preprocess another image\n",
        "            x2, y2 = preprocess_image_from_path(row2['image_path'].values[0], \n",
        "                                                row2['speed'].values[0]\n",
        "                                                )\n",
        "           \n",
        "            a = torch.cat([x1,x2]).unsqueeze(0)\n",
        "            img_diff = model(a)\n",
        "            # img_diff = img_diff.reshape(1, img_diff.shape[0], img_diff.shape[1], img_diff.shape[2])\n",
        "            img_diff = F.interpolate(img_diff, size=[66, 220], mode='nearest').squeeze(0)\n",
        "            rgb_flow = flow2rgb(20 * img_diff, max_value=10)\n",
        "            opticalflow = (rgb_flow * 255).astype(np.uint8).transpose(1,2,0)\n",
        "            # compute optical flow send in images as RGB\n",
        "            # plt.imshow(opticalflow)\n",
        "            # plt.show()\n",
        "            # calculate mean speed\n",
        "            y = np.mean([y1, y2])\n",
        "            \n",
        "            image_batch[i] = opticalflow\n",
        "            label_batch[i] = y\n",
        "        \n",
        "        #print('image_batch', image_batch.shape, ' label_batch', label_batch)\n",
        "        # Shuffle the pairs before they get fed into the network\n",
        "        yield shuffle(image_batch, label_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtkSEDx4xheR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_validation_data(data, model):\n",
        "    while True:\n",
        "        for idx in range(1, len(data) - 1): # start from the second row because we may try to grab it and need its prev to be in bounds\n",
        "            row_now = data.iloc[[idx]].reset_index()\n",
        "            row_prev = data.iloc[[idx - 1]].reset_index()\n",
        "            row_next = data.iloc[[idx + 1]].reset_index()\n",
        "            \n",
        "            # Find the 3 respective times to determine frame order (current -> next)\n",
        "            \n",
        "            time_now = row_now['image_index'].values[0]\n",
        "            time_prev = row_prev['image_index'].values[0]\n",
        "            time_next = row_next['image_index'].values[0]\n",
        "            \n",
        "            if abs(time_now - time_prev) == 1 and time_now > time_prev:\n",
        "                row1 = row_prev\n",
        "                row2 = row_now\n",
        "            \n",
        "            elif abs(time_next - time_now) == 1 and time_next > time_now:\n",
        "                row1 = row_now\n",
        "                row2 = row_next\n",
        "            else:\n",
        "                print('Error generating row')        \n",
        "            \n",
        "            x1, y1 = preprocess_image_from_path(row1['image_path'].values[0], row1['speed'].values[0])\n",
        "            x2, y2 = preprocess_image_from_path(row2['image_path'].values[0], row2['speed'].values[0])\n",
        "            a = torch.cat([x1,x2]).unsqueeze(0)\n",
        "            img_diff = model(a)\n",
        "            # img_diff = img_diff.reshape(1, img_diff.shape[0], img_diff.shape[1], img_diff.shape[2])\n",
        "            img_diff = F.interpolate(img_diff, size=[66, 220], mode='nearest').squeeze(0)\n",
        "            rgb_flow = flow2rgb(20 * img_diff, max_value=10)\n",
        "            opticalflow = torch.tensor((rgb_flow * 255).astype(np.uint8)).unsqueeze(0).view(1, 66, 220, 3)\n",
        "\n",
        "            y = np.mean([y1, y2])\n",
        "            \n",
        "            speed = np.array([[y]])\n",
        "            \n",
        "            # print('img_diff', opticalflow.shape, ' speed', speed)\n",
        "            yield opticalflow, speed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIJxEAsMxvkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_weights = torch.load(drive_location+\"/speedchallenge/data/flownets_bn_EPE2.459.pth.tar\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0LT78OK4cjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.init import kaiming_normal_, constant_\n",
        "# from .util import conv, predict_flow, deconv, crop_like\n",
        "\n",
        "__all__ = [\n",
        "    'flownets', 'flownets_bn'\n",
        "]\n",
        "\n",
        "\n",
        "class FlowNetS(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self,batchNorm=True):\n",
        "        super(FlowNetS,self).__init__()\n",
        "\n",
        "        self.batchNorm = batchNorm\n",
        "        self.conv1   = conv(self.batchNorm,   6,   64, kernel_size=7, stride=2)\n",
        "        self.conv2   = conv(self.batchNorm,  64,  128, kernel_size=5, stride=2)\n",
        "        self.conv3   = conv(self.batchNorm, 128,  256, kernel_size=5, stride=2)\n",
        "        self.conv3_1 = conv(self.batchNorm, 256,  256)\n",
        "        self.conv4   = conv(self.batchNorm, 256,  512, stride=2)\n",
        "        self.conv4_1 = conv(self.batchNorm, 512,  512)\n",
        "        self.conv5   = conv(self.batchNorm, 512,  512, stride=2)\n",
        "        self.conv5_1 = conv(self.batchNorm, 512,  512)\n",
        "        self.conv6   = conv(self.batchNorm, 512, 1024, stride=2)\n",
        "        self.conv6_1 = conv(self.batchNorm,1024, 1024)\n",
        "\n",
        "        self.deconv5 = deconv(1024,512)\n",
        "        self.deconv4 = deconv(1026,256)\n",
        "        self.deconv3 = deconv(770,128)\n",
        "        self.deconv2 = deconv(386,64)\n",
        "\n",
        "        self.predict_flow6 = predict_flow(1024)\n",
        "        self.predict_flow5 = predict_flow(1026)\n",
        "        self.predict_flow4 = predict_flow(770)\n",
        "        self.predict_flow3 = predict_flow(386)\n",
        "        self.predict_flow2 = predict_flow(194)\n",
        "\n",
        "        self.upsampled_flow6_to_5 = nn.ConvTranspose2d(2, 2, 4, 2, 1, bias=False)\n",
        "        self.upsampled_flow5_to_4 = nn.ConvTranspose2d(2, 2, 4, 2, 1, bias=False)\n",
        "        self.upsampled_flow4_to_3 = nn.ConvTranspose2d(2, 2, 4, 2, 1, bias=False)\n",
        "        self.upsampled_flow3_to_2 = nn.ConvTranspose2d(2, 2, 4, 2, 1, bias=False)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "                kaiming_normal_(m.weight, 0.1)\n",
        "                if m.bias is not None:\n",
        "                    constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                constant_(m.weight, 1)\n",
        "                constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_conv2 = self.conv2(self.conv1(x))\n",
        "        out_conv3 = self.conv3_1(self.conv3(out_conv2))\n",
        "        out_conv4 = self.conv4_1(self.conv4(out_conv3))\n",
        "        out_conv5 = self.conv5_1(self.conv5(out_conv4))\n",
        "        out_conv6 = self.conv6_1(self.conv6(out_conv5))\n",
        "\n",
        "        flow6       = self.predict_flow6(out_conv6)\n",
        "        flow6_up    = crop_like(self.upsampled_flow6_to_5(flow6), out_conv5)\n",
        "        out_deconv5 = crop_like(self.deconv5(out_conv6), out_conv5)\n",
        "\n",
        "        concat5 = torch.cat((out_conv5,out_deconv5,flow6_up),1)\n",
        "        flow5       = self.predict_flow5(concat5)\n",
        "        flow5_up    = crop_like(self.upsampled_flow5_to_4(flow5), out_conv4)\n",
        "        out_deconv4 = crop_like(self.deconv4(concat5), out_conv4)\n",
        "\n",
        "        concat4 = torch.cat((out_conv4,out_deconv4,flow5_up),1)\n",
        "        flow4       = self.predict_flow4(concat4)\n",
        "        flow4_up    = crop_like(self.upsampled_flow4_to_3(flow4), out_conv3)\n",
        "        out_deconv3 = crop_like(self.deconv3(concat4), out_conv3)\n",
        "\n",
        "        concat3 = torch.cat((out_conv3,out_deconv3,flow4_up),1)\n",
        "        flow3       = self.predict_flow3(concat3)\n",
        "        flow3_up    = crop_like(self.upsampled_flow3_to_2(flow3), out_conv2)\n",
        "        out_deconv2 = crop_like(self.deconv2(concat3), out_conv2)\n",
        "\n",
        "        concat2 = torch.cat((out_conv2,out_deconv2,flow3_up),1)\n",
        "        flow2 = self.predict_flow2(concat2)\n",
        "\n",
        "        if self.training:\n",
        "            return flow2,flow3,flow4,flow5,flow6\n",
        "        else:\n",
        "            return flow2\n",
        "\n",
        "    def weight_parameters(self):\n",
        "        return [param for name, param in self.named_parameters() if 'weight' in name]\n",
        "\n",
        "    def bias_parameters(self):\n",
        "        return [param for name, param in self.named_parameters() if 'bias' in name]\n",
        "\n",
        "\n",
        "def flownets(data=None):\n",
        "    \"\"\"FlowNetS model architecture from the\n",
        "    \"Learning Optical Flow with Convolutional Networks\" paper (https://arxiv.org/abs/1504.06852)\n",
        "    Args:\n",
        "        data : pretrained weights of the network. will create a new one if not set\n",
        "    \"\"\"\n",
        "    model = FlowNetS(batchNorm=False)\n",
        "    if data is not None:\n",
        "        model.load_state_dict(data['state_dict'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def flownets_bn(data=None):\n",
        "    \"\"\"FlowNetS model architecture from the\n",
        "    \"Learning Optical Flow with Convolutional Networks\" paper (https://arxiv.org/abs/1504.06852)\n",
        "    Args:\n",
        "        data : pretrained weights of the network. will create a new one if not set\n",
        "    \"\"\"\n",
        "    model = FlowNetS(batchNorm=True)\n",
        "    if data is not None:\n",
        "        model.load_state_dict(data['state_dict'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG7o8wqF0Z1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = flownets_bn(model_weights).eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCgWztw30gxq",
        "colab_type": "code",
        "outputId": "9686f40a-b612-4cdf-82d9-4c4fd2a156cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "source": [
        "framelocation = \"speedchallenge/data/trainFrames/503.jpg\"\n",
        "testframe = input_transform(cv2.imread(framelocation))\n",
        "testframe = testframe[:,80:370,:]\n",
        "framelocation1 = 'speedchallenge/data/trainFrames/504.jpg'\n",
        "testframe1 = input_transform(cv2.imread(framelocation1))\n",
        "testframe1 = testframe1[:,80:370,:]\n",
        "a = torch.cat([testframe,testframe1]).unsqueeze(0)\n",
        "model = model.eval()\n",
        "# a = a.view(a.shape[-1],a.shape[0],a.shape[1]).unsqueeze(0)\n",
        "opticalflow = model(a)\n",
        "output = F.interpolate(opticalflow, size=[66, 220], mode='nearest').squeeze(0)\n",
        "print(output.shape)\n",
        "rgb_flow = flow2rgb(20 * output, max_value=10)\n",
        "to_save = (rgb_flow * 255).astype(np.uint8).transpose(1,2,0)\n",
        "plt.imshow(to_save)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 66, 220])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAACHCAYAAAAP+QIqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO29f8xuy1Ue9qz9fudeUyAhYGS5tm9sUhopqtpgXdFI+SFU+gMoxWkTIZIoNQ2SVamJQGkUTJAq/mglaNW0VKoS3RZaUtGapEmE/0jbJKikqioomJgYcAwONcLWxU5SUqKG3Hu+d6/+sWfNfmbNWrP3/r7vvN85zbuOvvPuPT/WrJlZ86w1s2fPFlXFla50pStd6cWj6bEFuNKVrnSlK92NrgB+pStd6UovKF0B/EpXutKVXlC6AviVrnSlK72gdAXwK13pSld6QekK4Fe60pWu9ILSvQBcRL5GRD4hIp8UkQ8+lFBXutKVrnSlbZK77gMXkROAnwfwrwD4NICfAPAHVPXnHk68K13pSle6Ukb38cC/EsAnVfUXVfVNAB8C8L6HEetKV7rSla60RTf3yPsOAL9M958G8C+OMrz1rW/Vd7/ybgDAnJgOAQBtA/bOEe4yl5A75InyR2Xfl7encf20lHf3UiUp43718BwDblsdFwnw/4cXiPfW664dYLx25s+bNGN0V2GPl3SERjyendpoeqfubi8foZw//ZGP/T1V/VKf+j4AvotE5AMAPgAAr7zyCv6PH/tJKIA3bgARQJTEFuA0tw2vAtyWdE14Sa8lTQ3bkgdjNZSNND7efueuHC25uEP4XwuYbcq1RIVCK3dfupIMM3FFuTYOqxJZmqnK01ZwrgxbRVoNRN8+/UDhDil8hGpXOk901IFUx1qw46FTkC8gr2Se1P1ashCftMxbSSOsHsxeMqEK46YBtefDyQNRAzXo2BrNlLYRkxIr1FVDKb12gpg+zcHokSZf5uSs46PV4oXDlJToS2t5LVo6l/zRKJ5rzTwpNyO0GU1Wnsnbc1jqfK5ynLGOmJnCtcasPLitgDO131xKU7xN3vlLkdT3AfDPAHgX3b+zhDWkqq8BeA0A3vvqq/pGKfFcWkbst/wZVGkdCKv61G4iZYx0PrLAHfgP7rMw5uXHPEPsEi6dLAbdk8vreTAnry4r+PsRbCq/lmtQrmVYmFwSKXGHoe3wEBqqExmSFudaQyMUrhS/2IepdB71TAh6DcqgN5U7SD2PKM3eMInQr+/MaWAoxMexQrvgSFmn1jYCZKMIxBu7yLYvGDOAQJs0rQOw6tYKN9wTq3sgnQ61AGXXQnx7uG/LXOVgDVNK3Y6Sie6mMD/XrPV1vdnh9JHu2ejoeeQYotSaWjib2bipaZ5igkCb2ni6D4D/BIAvF5H3YAHubwLwB0cZZgBvVvGWCpzo3tIArUJCUJXLO2tbztdR2nTmECnuKP+qkKZKK5yu90CvMtalayttSZbF5HFc1jj+RNdtvpV76/dY3FwBfWrzxK7ZBj2Dna9HLfgeG+I72fOOXcm+cX18lD+IbiZR3oE2ZdQ2yJylniQQi+djvch9zHjOFlFbZi9DZt983rzMozKNx6HghrpsxjqCV51VZ3rWNLfQMlJMmhPO2NL3OwO4qt6KyB8F8L9gqdn3q+rPjvIIgMkBcadEvpzy32g87XWqslnxltNzJH+fI063R469PMwr3ytHKAO3cZd8PEjZ74jlaGcjwOKEKusxpetWW2psMsgigIvis1Efpbsv7cOozfLCqCDQxpOvQk0ajDvlDFEe4shedabHe8dRI/fGfTPzTuIjObZUYkSj2ToDbFTfdUaQaWtrOdeR6xd9tPjfY0W61xq4qv4VAH9lf4ZljVuLzAbOFB2OMZV4dq1oOzeKB46NSyt/K88Wbx9unjvzBvJxvgfsmbdfltmLH0fSbxmdyQ3uzKOrbRE4IwI0Kx6gJN2O1/EoigsG8hEarGw0QVtes+/cIO9IB4UumuWMKFHg1Oz2SAPQHl3b/ZaOcxrvN2Z6MCq3w4GARxS3NWb3Onwmg08TtXM03pf7NrUtfbLTs4RPnZs0YR6s2S/0zB9iMgkWIBZFtyRSE7gwFRrsyMeevx8phc8TjNvUg9gDuNE49mO8nUDt5x2lGw2ujLwc0TLOXnmMopWFiEfaHwyYrhD18RZoxn2HBdpyvDdpZBj2ungBjyo+10PWOvu0ABqE1DABkrXuOH4EaqO4c1C0b45ML6Ky2YFiIxDpp7q/iKJxxrRV/yitlyPmb95zC/neo17uz9C6rWCt6dIG81C2iwI4EDhNAZDz1Fq198iYRiAehTmHb0i7vCWMFegIRQoyqs+WMdvCGw+eWXkjEB7JsEXV29agvluoqi0P9l47WRyodeHeOSAl9fKEYiWNnQJf1qB7LElmYYtH3j0f9ekoLDIQaXpHe52nPfl3zRoO8LZ0R+zqFp896VaS8j8/1sx9dM63Lr3kizBMFwfwkbcZDjoakJlXG93vnW5tpX1WtFcxtnhkYdGsYi8PjjuCKZk8kkR6Y5p536wDkfpvypgkMMBTlFlhkIdBoAEEEiAEzUyGA178JgCRERsV2/HYksVFjTzwrJy7AV8ftweE945f99x2KGO2VVCaux6evVyCfqMl55IayhLZr62C5zW8KIDzAPRrtix79cw4/DmgrYHy2HQX72TPksmlKOvqoWE4yD/lswMpmrRGB928x3AWMpKN2W1Nh9imCvZtyMkMvC2TnHF3ynhPLt6Hc5699QDil+XsLubR+uGWun+ron1fY0lhO1ly6S6/Bm6y9Dv12/ctnNsjNE3ulmHoes8AiScv++iOM8478TniYUc0WuY4MovfKnPPssuwj6hDxl4RZZE2Le9/3itjJ9RWB0Se68BNPKqXUcauKJspSBvOidN3iB6IIt9qayxFzTtqTkniR/JE4SM95Osp9LmjhZG2w/td73y3NXJaN2p5Y4MBPH5piOmySygK3JwXq69lPsMKYH9c3WZfuOvZDAS3vLM9CnEElLNxfpTuAs53LZObk/kd9WwfYqpcSXaktTS8dHEUsPYiq/T1a947sjTqwowtOx3snLiwjpJG9XYiWvLxMkbxYf4kzRG6S3ZvBCLAzYzDFkSahx+FexnYJ17utKZdV6UNoWb49WnF+sLNmtPKkybdWk+t8Vp51FcZKXVOl/XAFbi5Xa5nBc5TeyaKzLS0YiAtxduSNnxYjvEYxPlrnyZxqjp6qOn9nvwjefZi2JZXc88x/DC0p/H3dtADUOZkm0c8kqfryxEzoFXeZ9wZNouxYrPmzOK8qCNeGRCPQDjSVX+9pccRz8gI9G8w9CvPElyt6+rt4QPtokf76p/U/42bvcDDq/TahUR0WQ9cgPNUbMoEzCL1lXpKAoCA2sC7/KYeCIU9TyCVlbU1Pu/iVO71yvc6oN5LvzMNCklBg73xuwD1qDG0D0rcsv7WodSwHzW8TOtT60rIGHnJta+DGUsoy6ADuZ2PzGj3AC/TXWaMWxMJGVR8D4BLaeAK4qUx2N8GvOyt6ZGudQyKW0DPaOXWS7yuuOc8LgrgtxPwD75guX6CdckEQF2uF7SNbPHVUXc98iw84Mg7uGv+Z0Wbyr2RNiPvTT2II7iJMHfnOZpCX5QSRcyMxMhePHpdAtrStyjO18kbg2icjJyGvd53JFvsza/aEztAc0k17pGFz0Q8+gO92pJ6fqvpsNV4AXCC0EFYEV18G6F53P65Kg/ECMDt2j+x5qbg45y2pnw+b0ae11Evd493chfaksM5ch2N2uio0dpsT2LabddDvyw27D/XGdFswg+RrK2G9XRCqI+j36it6wGDiRyRZw20s0xJE/dgVmVwZd5V33xbjpZXsrG6h0Z6240dbxCB7jlCpyPEWbKHDvPCiH3fuBA3/arJzWcXpxMG3n7vS6SRiuXQtzOls7MZ8zNYHmEb4VLD/vS+hWzNJxtkEYDv8XizAb1numdhD+kZ3cWzP8LPeztR+qzudzFsW/L4PN1gL5FbxjeTxSvMkZe/fCFeP8L0Gw3A22DvOpOrRQVymQgWfsQbjsIZ+JTK9GVl/CuV+s4uwqfJGJsckZ8qSADbWVrxBy3V2wOj2JQybLzezDBgc5Fw4fEIWO61rkMs93tw7eIeONDaIC9c5JkvE5TtcDu7y3vxnCe7jwB+D5Bk9bAufmigjiiqhy//IY0PlxWp5pbR8D6Ivx713bOoR0SHDPZDdvJ9PQWXP3NGHor8TMBo6+HbEV4MZLuaJlT8QJo9OyKa9hyljzxrE2W8DLLQGevDzJbriB4FwEdg6T3vLW856/T70FY5Ee0Zd9l0s5t+B2kQhI3ivQfuee/xyrJ0d/G+Q2dmUBmli8bzipyrzDJ7L3inV56KtSP/3hld1vi+Pp2zk00lmUfWllh1UAXd4WCWTygu1NfMU3fKt3c/esQbaJ0zcfHd+GnkoNiZUlnCtFOpAmr3EuhTP7Xo7URphCk4jko5R+lhkTUPzP+eIBuvGD0KgDNlfZwNoswyj3h4gxxNzaL73YMxoBGPTN5Ijrt6S3d15EaG5SGpG/w7aKvfAIRH0Xbp9pQr8SwqxM8AeBHdBx16pG1rn3oMSuTLqMrqKsMgNNpj3+j2wItoWOzxFpxIHhS5vE539k41urDIM/cXMuCnvTDq4jvyteSlkz7FSEsuDuB7Xln14B0NxAjcsgE7ArOt8PuA1wi894LzCEC28t13RjJqT1/WXn6HjVLWYDSmeGDb0cP+RMtDdNeGG1XO18NPkfaWu9WxG53FYhzpi5HxHM0+svBoTG45ZB0wDNsrmQKkU7G5TVMVihGIEzgP2kdDC8/sKz58rZSew2+Dslt6tMOsjoKA79wM1Dn+yDjM9J6VfK/X42UYKfaoe/Y6FXvoyEzAl7dVj72Fd1i81zIROGfR4hp9NJOIjLNwRF90W5bloXLCJZ5Bx9suFfO/bMxvGhtLI3E90rIC8QD6wIoTeUvPmlWAJjCXw7x87i//IQrvvS83exRly9OlUdxUMpxTodUWyhApb+exOxnCzwYG/MW0IePV03MD4Bl5kBt1kx87HoSjgRyljXjAhfswL0sUv6UqWb4jZR2hrT4YtUVWl4zHXlmichr+NODrOq3E+UO5dNCuxKSO7QhQenF6h+TotGXHgGiyOFCO2siS7fWMR0fRRn1fDU80m/BsAsNqhqjyV9SPfIRefaZ0m0qW9NKmqy/0R3EhKAVoYd5+Z5WjmYHl34MMKz3aaYQjbwgu3Yzlm22nIN7nSQdUUmZmIEaGY8trjk48QwnPlpDu4llvjJl75/V15nY7WvYIWLNyorRZulH44XYKFGPonerxMn1b7N0Qwcy3DHwNIy98pMcjwzcaCwzoQF7vI9793Z2TrZxy/2tvhWrnndpIVSyn9/nPXvgWNJSLllDG9GjbCPfGK9oq+mMivX18FnQUXEPvAeP1/6yMUd0iNeu8qh189tJDG5nmQwz3FWJDuOrh7c2yUU4DRkGHpzswnGGIZnl7GiUVLxgQ/plA6tUGfDW68UiczGqSIto6e+Onq7fe5IisSyOHm3ZwkHAaCfsrtohBhe1NK7/XnHe7NGylndpE3vo0rzwbxZmKAchb99G2ER4dh9Y+/p2k+wJ4VF4KOIM0+2XoudwFGCNgztqCw0ee64hGM5pIrr38t2ZSI95374OEtgBY23ZXd+8F32rncOUhcPIyGUPwDQodeff3NmjGh41SUJ7H0rAa5JyG538MlyK44QZziaFFco0v3ls2GX3DK5bjVYMyJuZfrvnBqK3/abluFMh20z9nAA5sA4D3wp9iAe+XXPjesi5NW9NI/70/302Z5/wQdb7fFHXMIwp/iPKOTIyfFUmitHuMTRcZWcRNAcZpR47RvSkyTN5hxLFqHJJ1bwdvTUG9ex9OoYJpQVqG9oDus2rQM7UobZ9iN2m2W+jyH3RAvsQwAj0DuehDp1H6jPaMm8wrzO73AlmWf9RNzCdrNwvbMhp3oYcAhKPeepdOAh7eMfIAM+qgUUOOhHPjurseeMcR/85P3NEgtuy02abOtY6qPBp/W7qWlVed1kYh4zUWPvKp5eM6s/GIsykKTwH4fgC+PIVq9GXv6MxFaDo1Ulw+nY87dfKKjXhKU2gTwEXkXQD+HIC3FXavqer3isgXA/ghAO8G8CkA36iqvzri5b3MbCrlx14G+luv62ZKuKdL9oxxTut5RrIt9ZBUhqys2aXhdurGCsVlg2+knqN7bpORt5dMTMN+jcrcMuR2PTSiEsRb2JalG89a2/TeWeNo4sHb5e4ID7GzyGVxnbVNFm0l7ORNZMrGWdO/e7yeLtqBbAEqpZdf+rcYIy9Z+76rr5VyJ2zJ6dJmnRvy8HmxKluUfmaBZQV0r+CS5C+0xwO/BfDvq+pPicgXAviIiPw1AN8M4EdU9btF5IMAPgjg27eYZU+q7d6v+tj1S+i/n7fHg7Dr+3ihd6GtMr3h2osZQHwQ2Dkob+RtZWUdfdEq4s3pDHT3joOMT3RGju/vDIBGfJHIlqUf1sNhSsM8abTGkAVY5YG3OmuBFbCXAruZd2DpuudlFO+dZ65GJ3REhwZbMFIbNx5k9fYyJjPZvNEFNGvVHvhrsJV7Lnlcuf4rNKlRKCNTtAd4fuh5msu9rg/5FKgPMb1XTrQJ4Kr6OoDXy/U/FJGPA3gHgPcB+KqS7AcA/Ch2ALgHla0pGrAeUMWewAictgbyswbzLf2O5BilH3m6mdEaAfYIcPfQXrl9mshh6jzJLUHceDxa/z2zkmHRWYEJ7wi4wzpKkD9xAKtz6Yphvmm/aAvee9svZNQIhb5DRiTFrIeN4dyZxhMlwaOHjF4+D+BeyPCEwsCbjsS0/Kny6PrXHCBDctn5yqKuPnadvc250KE1cBF5N4CvAPDjAN5WwB0AfgXLEss4P/pTBTMw4DYZnfPNYZlxGCnmQ4B5xDPjOzJamXcXncQYlTuiLcN3lOde49uB9w4euwUAwsHTGYdkgPm2iL5t6cND4E2ANixr042nPEG67LnWsPw9HcXl7UVyvzzRpPWN0oOkdNOIZTRLvQ+0smETvbVIHjwDfvNNRjMCBLARiFt+JTmUy/VysmfOcQHIV6+aZOEtg3b/UNsIReQLAPxFAN+mqr8mpF2qqpKcli4iHwDwAQD4p195pY1z16Px5m0tG4Nn7VEzeSNyBLzvU+ZWeNRm/itHdy33iGMV5T8at5tG4H0H2mN8LqlrIW11+p7pVTTYjlbssFL4EZyN8iyvL9R7qoXqpndfMbunBb36EHPgyQ+tN4cJ0s/UzK6huqMBpMg8AXKmrJnbutIuABeRJ1jA+wdV9S+V4M+KyNtV9XUReTuAz0V5VfU1AK8BwD//6qt7jnoIu9ry8fpv5lgc0est2um83KmMPen3eHaKuN5RmA7i7kojzAjjaEzVMSRrnmY5wQnZvVHoxmlTZqZEkaBb4e76XkC+txOCQnjGP/zQg7RtFKa9C4byEoZ/uFFBR13dfIP5TtxDgZarEhgST3X3Ia/+MmycsI1cYARandyFurWrgJclaEA8pj27UATA9wH4uKr+aYr6MID3A/ju8vvDW7yA6LvL63UG3vbrwUrQv9jDFI2TI0sEW3x9Wi/rkUEeTODCuKOOj19+MR5beOaxxfs+I8OBIK0voPOlHsKayMrbl2eOlv8wtmgvYzUSAe7sbvuHsJBZw24o8y4dYezLyhrJY43TdF5SaUEPemGaKJALLx3IwkTKw4YjUgbmm4FRk2Vj2qOyPNhk49EAgLf+7LWUe3u5RydSwCkt0miPB/47AfxhAB8TkY+WsD+FBbj/vIh8C4BfAvCNO3g1NBr8XiWi6SxcnLWf3/Z0FPRGdJ8xmU3Fj3j5Gd/71rHT2USezKA+JI12R7A87KyMiA1WVM+uHuREPjNihX4I4xWwvheNFKJ5IMfeLHmXHvR8PcWPXLuUNb57AEm/YmlqgWs8yxWBcS1jLjyCjZIqS7xO24Zl5HlG3ktHvK5AyzDcFgnt2YXyv0diFPrqrfwRbSlYBArRfWQ8o/A9Cn2fcbQFdkeAe09cVP6RGcMe/lmdfFw3Ll2aeh85JQP9zGaYoWefobPLFEZL334NDjk2R3RqM9EdLKCfEfiI+zkGCeh1gdQK7AF3C6Tunj3j2phCQFx42H0D4BkgB/epN21GgRCivtYeedYlPj1IhgrIdC8aSLX5uOzANa1LRA+0C+W+JMhPFEyasObjXyaumu1W2QLiEaB2g3mQntNEYffxhLJyAp8llG+PMfL5kkcwQ56H60lM0pdLIu83APLIQRsVmzmGnoeFzez1FwbesbtTH5ui7fLYsFm55hX/aIqaZmTPd5BJ3G6PKr81UOYtW3pKZ2XyPmg9tXkN2CuIB1q2xytmGWoAvzExu1+nkNU4pRZhIzzQLgW6dfv0egbkFpj8p9xXuvhZKLYmm3nJHoAz+4QkzMqIDMJer9M7dAqkR8Q+C3roGUOWdmScfP2jtFuzJB/nAXsv+NVswRg2UPZvq4b5B7INw6Px5mQ4RCOBIg9iD79oarJLQTKXlsHdpWm21ZkVZBB3o9q8XAauSYH5Bk1l1ZU1fKtsUMmwU4JR0KTziDGyshvAy8ajGi5fjh9dRmcKn1HX1xO6OIAzUPvdlJneWlwEGJnd42bJBnSU34P3XYh5jAb3lhd3RIb7yj1qq2ioROEpEDrg3pLD6wEfO3vEFwrLyjolYcbjLuXXJc6pSx41aoapR6aXo4ZqPMCAYbSuzckmoD4NjjyuVChQHg06l4yAxXH+sK0jYGYEGGipTKV+0Un9NAOoWSUwZsZa2zi/7LLlQdXZCr3ZGS0lOXrUJRTBam8iQOdfQb6jgvkZn4wXG4IRAPgmy14HP0LdOErKuw8IPwQfI55ojmQHpZMgXoFwnTvydwA0y5T1+GXEdbOxs2Upm/FOl3Y7esGsSRuBawQsR6YYzHfUaZk1vTOxZdUcfLsdJLL+Wec2nmIEqK6FxR3+YFMptTK9mNLLlzumBAD8rUv7NIzdm2LYIR3BqUPeWa5aTuDqtzaxzJMZJQNoM1jk4oku6Qy864ym/A706FE9cKA37Pb9Ch9uf0yWxpr9hngwIPBY2jumtrxKny4Do9G153PUQGQGIJPRl7unXSxNtAo3+gJLBOz1Wb9S2bKcZ88+E48H3vfsz99WIHx7cPQBgwaEtY1nb7uOG0nSMMOjYP0QtMcbzygCBvZaDXxA6WpY8TTNW67Ar1h2bEjvMVrHngsP0cX7tTL8+mT3AQTHh8Xz4Zynetegzuy0oVyeikxAfftxFlefoowzGTsltyU6hKZ6GIUmbWUxIzKXetcjAwTrs4fn5CEmsNbRzjn3IBB5ujb4H9K7ZIp4eVwYjZdMr/by9vxHQH+EMmftqDF7EHwSAmDXmB6UM4vEcvgkDL6CFviBFhP21KWWRR2RbW8MmSbKEhqAu1jvkFnAt6M9rj5FN09Idf3xoFnDE2+0mRYbeCXlWuNHwGz3k7ZysIjRkgNb44ifgJREVlD1AAwAZ64j8ZwQgzgbSyuzU+TCc6IIPmY2ocsuoShwUz7zJje9XJGdyRwc618GdjYCTHvBfpSu6k0iJ6cbgT6fGpn1C/kNqUxHxvt9nLX78OB+8eOHj1c9u08Jeh4euIHVUYkMLZAffBYKyAxKuGADsLfCjtDext3yYHZZ2gh5sXp7isWTNkZ2Sp7QHMwAmdc/a9rgOvWQndwa5GtkpOszsL78AnRr55b3REbH8tW6Kc0M4JTJFOxMnjDXjWYP1YsmoK7TTFep+kzBu6TGmy36tPJO6KIAPgH4PGpIFXW7jxQqilnak4LPAM4QaPkDJFRDM/L+U6Ber/118PgiBYbx2WBxGXbP4B91XzY+vZ5Hafd67Hf17CNs2MIc71xEOKUbApk3bTNPf8BTdKoe52VhWBaOrzwC957HY9r4meA+PuAf3u+hEVhzxcQJoUBj3qpMp3b603ix1GgK4B8h/sJKtHTSlIE4nok9m2hrERcxm2J5b35eZb71MimaB7Mz3NncVA+bxungfe+J2rE59tU87+QwKtsDbn3ELxdZ/ml+vgBcADyxylhHNSMEwGluHkbPWD6n9gZMZ6Sm9k0TfZqMuftxknnsBrYk1W4ngXlkswZ/nd37MtgbjYxX5sjtccy2gD0C76OYE7aVB0qXcGQk6gmczGvQwBEGhNfkBDGmhfXd8p7v4p3vzRMaksiiRZoVFKKD+ArwAN7E4m0C/TcfI0M3qg97wD5/9CUTpQDztgX0bJKVR4LpuFOuZkBLm65685kFgtM3l39EfBqh39VjDE+IPT2ix/kmpsneILCUJ5UnqCjthlx6LgLg2bHImszbRe6OEeBH916PfP4IbI1uXX4PHlteZAay3DZ7eI7oLsCc0R6jcd+ybImWl2SMuX+QKUjSJiC8S76taUiWPlLah2r46kkGvOtSyalV3q16cDobeObID/BtF++oDJ8v64zoRNlJVmDwRqBZ5iGQtnjjmQ1w7yGcyUM+y+pR2Ov5k3etSvrq9Zc8s+UhSFYBTmdg8msKK10WwBtrGyxEzALMM2QCJpqbTaI4Q8tGnzX8VP58W/NW+Ib9QCzmEQFslC4qA2i7q3vATrJzev6165FX7q+9HFtjakQjTDmKN5nMR/KBxoUndhrF/ht5zIh5GbiHMmSNGQ7sKA/1kAm5NeXJyHsPWaKRbKmXvcWXsom0IN7EoR0sR+q4N086uCWZIrNH7eLYofS8FeRNB4bRHqYCBN4DYevyjO14Udrtgl45hx+MeAwP3Bbpu69pWMUUokIAt6yHP8GMCYI3abB64dkjj7xiBmcqMRyXkX4o0C3beF6C7W8Ijq7tnr1nlnMLEEdeuoVn+jDid5S25ByOTxfZnHtEjRF+65XB2/PBuF/a5HpYTs5XEzSWIXL/N+ihvfJhGDVuo0jSJmeZ/NP4aMroaU+aTXFJxu6TZ0proIGR6j6zRn9RmSPDzQ9xGgWjjF1+8i5U+jX4qjPlb7Acc3kP/Gm5rmtnptBS9tNPTimWVnlpUswCnMqakLHi9n0TK8DytvxMTU0MbgTOz0tzt1gfkEZeKDuQXvUAACAASURBVHvU/KGJ2yQ8OsPFy8hfIvI8onqwXNHyIbDPCDwmZfJ0MyKHxpKE+/h0VjOaagxphECd1Jeh7k1LjeOa6eFUZsCOl2XnaW00PQRyYPbNYPd+D3HmeflrLi8D1zr4S2EjcE4/eiP9Mq//BmZjDNxUUVx8JOjwrdgC3gMVujyAV0Tzb2aVoFMBctoPKcXaTqK4KQe7qAimacJ84rRL1lv0SxSmL/59K45XxB9VZmlv0PZpBIzBqhcE+Vun/hm3NQXf2y+Pny1HJpphjDxwzhPxjeI21HMzvuGtxDNIoMxQ+/qLSyscSXESNJyfuXZy+86MUm6CvvNk9yTfkzbtYHOOKIF/KaVhok22JpjfrmO7EMkYAWLU4X6Q+bQj71eSeJ/Wfw2HmXT5tU/GPPwbYhD0Dy5phlUNlXeh0O6SmGY0yzTNl4IkqcNCj7QGLutSipFtl5lkQbQnLu9TQKA42clcIsCNYH655bO8sbncs3c8yVL0GwDe5M/BwcBQap5ugwzWB8LRm6JAr4sj/c0cEq5DKxuqbPYXvZW6x9fbC7p7MYb5RaAdAvkG8+ZDKyVzCuwR/y1yTlKEWyHHrHM5oDm/I6voVuseBHqftjlHOjD1kWX3HWUdYC+tsNKPtntlMvn7zI5w2hGA875vh6nHjKql0bis7sUkJ2xzZKXLax648bH89tDS2NVtjVxhJSP1PAG4LaGYQrC3oFifTDYALsA8Y3ltlTRNZsgTrVtyXsaMlzAvT215v6coZJqhb5nxBTcvQU8vAwD+MZ7g1/FSs8zBesNLKDYMTuidB04rjkf0ENzr3BntUQHswTNYT1i9dX+0wAjAvH4fAruDFPE+UqbfGsheNI/NIx/3beo/Aq270CGrt9fMBvwjioA4ytsUa2PCyyGu8Uv8rAtIvYle6bNDcrIXsziMp7rRFNQGi8/v+drAiwYDv2zE4Z6nvZjjH0J2RsTSdBaDBDZDUA7KmmbUr/UAa/7KU0vacj2VAm37okiu7HisbYTA6s5W2WYsW5zmstjMQI0FvO3PSARiX9UoPAQzcLpd8wILX1XIbemtwuNmOuPJdMZTnEJ9G41J34XZ3vAo3OuhgbHpsYG2VxUeWl42cb9Reg73uryFZaP00Rj26fbwBPYdKrXFaytPx0MxHCRNxsgANNeOTyPYjHpeSEjVbQsKLvHDjlL3G8UZHwdGEi38wQHIYGYQKX2mNHYdGZi7GtNmMCR9yUBsASZH81GJksbvAInWo7kNLR+w9rG9bBT2G6WxBMxjR2M8EoArrRPQgS1yi/posrq0DGdK6cv9+UyW0/ahnNEellPSPmXTDEyY8WQ6Q3HCXBpQ6P/2Kibf1DwEvQHPtpea02KULaFYenNweJzM6B2fkewjuMp4cL04bQaQqb9JCWr7SXufZYkCInUX1fVeMADNiKeOG6hJbwM2Aj6Kr7uuCoinNCg7Mx5NYIKujQcYlDNRGHviMi3rj/WQpaR8Vo5oe2FWF68s0UCCSwuXJuPdXI9cDqB9wcfqmoCvKMIzYhC0kTreEWkxFral0MpQPIcv8vC75F2j3ayegb2ppPafKRTW3wltQ5riTQb09lHQ4qVrcfuF0gM4QzEXxk+IvZ/ZmRSj9WfB+qDU72Qx3fbDLJoxHnFEWNfv68B4uSLHIbuO6hU5WZtyJE7fXet2JxpNvyKE6M6K1tX7MoZyIkMytwajXvr5ki9P4k7p0iVkR76eXIvWtVyvCdreBuKExfptVhH5AeXBcmtAWFMlNqsNj9wPtGAdKR17SpMBredLZbY+YpHRG+WgMioLPp3OjhcL0NPjATiwNAZ71Eq/0d7IScubTVgbJrSmpWeb/iheBJ2bYA88T9Sx4rTN660HYLv2Ww5t22G0jOeXDrOdL56E/oDeA4+85Ui/Pejy9Q4I6OTZoghvOgzQ9j4qyzNlB7dxMoO01Q8A4v3jjVA8mCNJNjw4IN/DGjmCNlAVGHrn/sFdJ4ZNY3xL75jXtNMVCnAAZb/+NWggV55IXu+xc3jm0ey14HyI/Ei4Jp2rpwL1TA9/NgooD9eDZx2scPxhZDOUmY3mF5LqK/Z5xS//ENMU/VwClKGPNKIqsillaaWTeyqhrqdUgPnkBqC99eQAXBRPMOOmvt8pRQqt0njJ/HOR9o1dgWJ5Y/QpYrtZVuk7dfIzTlMVD8ps1lhXsvw+bvRpuGws+fTZWHImt8uz5Sjx2UtKCVL1HYJHMCC3BGnuo9qgFcyXpf4aq777cpl/s3/YBqzW6Nhj017m1DL5dOW/aD9lV57zRoF1ihm94R31iW3h8mRGwIttywZ+CI9AfNPzcE4dZ2LDbff8hyC+MbpY+oy/UWH9Pk1l1mN5DcBn8lxIrnOzv3BJ9xCfVBORE4CfBPAZVf16EXkPgA8B+BIAHwHwh1X1zTETBW7OBSkE7a6SM5YPeALrurdVxKBFgVs6oL0eUWdJ7UaX6U49KcxA+8kC7vOphk9QvAXnKsVTnMsDxanRFdO1ZZVe6pLLAtqyigDgnMwfFQuwP0Wr+4J1843lsBeMTgBeKuF2nelyNBa8PxUZBrg4lpyB3xsPf7RuNoYsX6SGzTgtCfm5mXWzP6uotr673yQvsFWEeK8zO/ZQ51W/GueAl0LowCeP/96IrIwBOa/AGVn9zFB1jvbsOrcUql6Ttcxkg71MthZrwU8BvCnAr69ZmzVCL48NXa8MUVqbpkbejFcW2/4V2JZaVb7O0nFa9r6iXSze+7FB6r0g8+Q7BS/hQg+uaxoH1NbxfCa5Affgo8ajpymevhXAx+n+ewD8Z6r6zwD4VQDfsotLXd+mkccdb2A7zViPU7RfxJ3I+e1PjJes8RW9FiW1I7JOzd9cryf6XY/TmqHNPwS/q17M0Ab8z8GfX3I5U/7IGZDBn5HPd98/z5PveTa9N7/POwuaIyFq9+qKp6wCCH45jy+8djs8KVZvVtt71TasXgN9zVwNm+U9WX+iZT8PPhFrH1c/5SWrPF2jWh0owLbXph1WgOMsy99Mf2fHO+PhyefhvFG4DYqnG382oLYGijVetuRqlO1hrQOsYJfMKyZN9ofgHoRLUh4GI1BiCpSpxa3htGOnBy4i7wTwrwP4jwD8cRERAP8SgD9YkvwAgO8C8GfGjACc2JPB6iVDADHP2HrW5eWHm5aOXcN0lFqYLtbsZi6hS+apILuWEMuzdrdUsDW9WffOLA9AlRRj1UNbLtHKg8G6ASq6P2H1viPPnG0V53c1bq7tPnoAG8mQXfu8s0vHxN0yGjpKFxP6Rx0n7vKIQVD5SAXawnxedXFKRj9oTcWqU1VdSWfrQGSB2AAA/cc/ZW2o0WfF/LXQTfTgb6JALRE6lbeeuZwC2vwg1a/le5D0uyRGXjE/tInW/Ji/lc1puCzeexvtwR3tR/UKy/3ICcS55hNWp7IRuLRnp4faJmMBGkNDb4A0h9Kfiw7efwnlPwfwJwF8Ybn/EgD/QFVtJeDTAN6xyUV0AXBgOYYRs5seKJYvf7gGqtM66acvDNjV4olrINDFOgcyf/tU79v173WZQ/EGBE8huIUUH31hegstu1i08lAC9XNJp1D8OqZqCCIc8bpqyyUewEdjhvNHTZBhgecVNl9AHpijtFE5PN44z81clkwGjlLH1Kcd3WeVblx/VwsF1oP2ZR1kCizLJlr0mfOUBS1brgM7HwaSxm9uAZzl9A2cdurUpgFQt7vNhJZsIJpqkhdo3jawesOczM/+PRuWAWiXXiyNIvZk2Mu3l/4i629DmT0doAV1r1z+3RP7PaNtD36hZ1K6V2AumFXrWcB7dsawArsTwgxot1RmFfJ6BNxrF4qIfD2Az6nqR0Tkq7bSB/k/AOADAPDKO9+1euDddEYJjAtoN3GVIwWbG+QhRFweizIPSGpSge07WfJY/9q3f8yz1uZ8xFUOLXluSYYZWr8itDow0iybeL3il09fAvAWAC8H6faCeNQyPn5P2CguW64dzQY4zGad7KSeTA0oEx/g1/T03soN7wmMvRo1Hpn3EgJ+HrQALB8+KODQ6KvzfEcfA44AvJHPtUyzW6U8CKv11DVNo0ClXvYRhHOJ5L2wnaOEtjlG3oKvl1/24HBeSjHyMwGuMqc1HGQPwS78sw6LvEU/nbUXdPjBUmr86a9uJw362TJ0fKzvNdDNQN+I9njgvxPAN4jI12HBld8A4HsBfJGI3BQv/J0APhNlVtXXALwGAK9+xXu1euAnCebfZrWcx1AbkiqjQF3fqw8ri5fTDDwQSpRPKpSti8sunRm843v1eBfepjdPSqitaa/tvPTcLWbKBbxRAFvKw9Al1QrivN/8LQA+H+v05vNKI9+UtP+YZHuCHrwjsvjoedKIRjrKY8bqmaX1YdFyz6SLPa/7jXTxwBUtBnlew/sITLcaIPLw/EDyY7FpjKKXvoFMd+3+rPSQ3oN4ImcE4PYrWRrHW7j1s4rSDOBWVq979WhW4geKjCDZszZL671tD9Lq7rk9oyml8YyepEeDxHs+9vuU+FUe0q5ZA4t38QTAzbQq2ku0JMyMrQ+igdoNEjLec1miMRnG+L0N4Kr6HQC+AwCKB/4nVPUPichfAPD7sexEeT+AH97itVDZE2lTUnvSWsGXQRxYoYIUrNStroHb1KU+5QqGvaAocqsloufaAaanNzJjEsWp7E6xHFJac1kcWco8VW5rmWec8DImKKbSwEuez8O5zu5epl0uJyhuIHhSQkzHTMqXqcrs9KQOI8Z4wEuRPs4TQ42lZ+fJ61eGcx5vgNLstKkIKI5fIEi0s6w5WttsdGZBsgruia/M26Amsw26ppFoYAKL/plHJ5TH8/CurLoWTo2Uxtfes69li9uiJiuoeo+XZ/fWxlyXWhbWAWM8ojXD6LwU0wdrx6hM9rQNwD0xnrqmDA3iU5eGX8BiwD8BeNOtdU+nNQ+f32RbqczINdulpJVBsFTMP79TXkCN6T77wL8dwIdE5D8E8DcBfN9mDgUB9i3q01aARh9apbbLEF0MmLlxOD3xFkpfO9W0UNvsCojM9QV7BXCClL9Fw1a9WIB/osLnCvTSzOQ+H8ANFDdYQdmIu4r137YTclNE10adA4i+6SInLkoHl84DuMkQjZEOrBO+fstz3Sbr0rqXZ5f0pi4KPn14oC9B2Cg+E3pEaXxQq8aSBRm9J71XrjA+6Gk7LImD2Toz+T2lvtP9tZdt5G1kPHw5qRIlZXtvJdr3amvtIwVnX9KU1PqsGjNdv5nI+aTEGY/JjRg2No0BNiZjOgTgqvqjAH60XP8igK88kh8APRDRsuBJcTOQjqK69ZA8diDejhFOt6Q1Eksl0LoSXKaf3wEnnArw2kLGstxxwvrw0/jQc+WG6xnL6jrjzBzksXg/E+QZo4eE2V2P9H2VtI3zFJWlLp51NuLrWxdYnasMa7ovS6GvL4czbav9TsoaSGkKzUe38rnNnXcZVMgXFr2c44E5a7QqsPZBnnhmkHWqB1j2jEP5Kc0Z6zILi+WXYxgcPQ/FqiSZZ8CDIVN2PtfuButXYKyeNsx5fzfzauQrglk/WzpbF32T8Mzqf8JyMF8FcKAemW1pp2nFsfNMYF62Kw7oEQ6zKi1qgt04b6DxSgpNpefZ2wboiZ7ztCdpB1NVmJKgObOZZDGLWOimWRu3U8ZtM+FUwwHgKcGiYir+dzt+bmk9/FzLX/KtYW1V/HjNPGs/tqN80TVceAZ+3knKHB4fJ0l6Hi+N4ZH2MUbNF3jmkw7kcI5OjdjrmQcOa1uIG8Repzo+pFvdGdNJeAjYliYAe++gZHIA4+2BmRGRJL2XF+jXmiOekaje2/Xys9y8B3xkWIx4F4GXJXpY6xX6VLCDwxpvnfrYnFPDI8OoG9B0mxpTZXkLszEe57LVM6/UhQFcnUUhyzQruiUOoEeAZh+4oNv+YyDdKLM1ZgYnFqT1evku55ru1AxAM/9FdMiyWl7H9HoSHusjl77C9gL55pWzOCNQ9l0azXzvcr3Hm5UkbZQnanEfZsdDmPwz1m2E2dj0/DYFGZFv1A5wpE/b3BcpuzhyLLgmKYCj75DU2gY89nRIpkAewLPG9mn3hGcKMzKcns8UxAPxWjpDzOjFh61wk4EdwGbPA/VBsxJQsGAqadjJnLAot/f2FWifSZSCeZk5oEcAcDtt6wbNCzuTG5Js1fyTrhoOGhwlTLSNB5YHDfXpH0OH9GlZhqb3y7WegfPNOjjL3vR2t8faK1zSqV61O1lsJjc5jbbvb7LTEY2/bNx4afZcZ8DsgZQNVATOoN/TII0nAbpJlgDdqQnN2+57gXpEW5ZslBaIvcyIshnxyPr6NCMeR9qCy4h2cmSUlcGKmH2CLeLDvxGA2+AxvhYviNvtKVaQ9U/shXhsrTP6ekYvCLFhaeBC1jCebt6gHwz8AtfEEVLw5rkBcFmBeubecXGKFlT5LAFr8bqPVdu0aveCdvsUVg9dfAuSd91ond/jVH4nRbP22dTEdoa3+yaW/pkaPu2YFxpDS+q5eOV+bdtVavf48DXxNHLOomfhmXfN+cI4bZ2VugsU6FYmuCW7N523AG+L/KDZ4hE1tJrkSf7I+81IMHpnY02TWdiojC1A37Loo7Iyo5XVM/PAMwXtgI7CvAH3D5DYM/a8LY5fy2fKXraYseBL45EUZT7NrRM6Ga5IC/zmjXvjFu2gq89EnhcA71yoID4KFEH7FN2ixFWa01Dr13IPuCfs2QNoHsUFZyasesUnorQUxawv4SuUetWfq7LyaOtgRsOHxHf9OB9hCnv+o81MezAiG6sdr6Arw/PwPdjsAfCR5Yqs1haPkQHxYJO9Gr9VBtMI8EYNu9eI7JlFMJBGgJzJksmwpRiZd8BhnfeLeP+6r5s9wPQAbi8CZYPHr++fdHmW1yzv0ogJ/MXYQDpcmbHZJ5dfQrHPndkDAdvvbQDrz/K1CtUdK27U8Jp6vfaPzNfkx6bbgfYI0K6Bxy7RAsBC932Y0VS8dvY6l78V3Nf/1zkb65CbnzTSZ/0fbTZg6WwJJ5o1ZuN3jzPlZRp1SzU05KXXi8gK5bbs/tTo5c704q4VeYX3GCIPAJEsWyAd/XK+TL0ZwBTtcoaFGygyj4in/e4xvJyfZWTgNp62ZBG17wzeQNa/KcfpmL+lf1L+ms9nyfpKv58SRueS81ZDrlethLR6os9uH/hx4rNQ7OhNdb3aHJ7eRpWINqA508G2dxWIEUpT72n6YgajUaSyjSf66Kslo3V0W+ZYzzyxA6zsDMMVfM9lJ0vvGJxLvrWMFuxX1GCT4NfMPXFuP/bsb3bpWfdtuc6PibrioO2S3gR0543ZrhKB2xikKzbwEe/1/QfX/VO0tDDyhiOvx794wukjcPYgyWki4xGtI/sGHlEG4JFco3RbMwOgP89hlCeKzzwFcX+ZXBFt1YkVduR5sLJG6W7oXrGe18xlRrKcsDie/vuHE5bnbM3yxxTz6fRCnWGa+rSDdrv8EkrdXqBBBe2NSyDUkLAi1Ht2HnJ96Cnrrzhw57x1dSRwjaS7APukBt4t+E6YAwA3sF+gWchuTJjBZ4xbLn7nkyWwXKvR8FJ6JyfSIx+uWBwMy+sP07JEFm9HAjRb8pW+CiXL85dIBgNwO31TOJztfFvlPGy0dsyPI7znnl1HNGpIkyHL61RuN38vT9RxnGYPD5N1j+c+KucojfJs8d3aZmVkdYpeNFD04Cvo36rT4M94s9df+YhzJF19Ip2LHIGs7wZ0+X3gVZHLGQLNw8lpvWy8Dk1e8inAXAFcyAq6NwnCQRMAdjqv47RtPjv4ynIvO420cRgs19z1XM9/fT8hQrF1f3kP7D3XDC8i54h6oJJ/E9TyWr4nM5qjaFgAIeW1yY8VxuU2DzSB8PHIrsG/J95345F8/Gs8sifMPp1VNGvo0QD2YBDtVx4BeMZz1BZbs4URXx+3562yLfI8IqMWycFLLDcuHfdhZMz8LMXAm2XhIwN8fv6LoaN1LIDxYA7o8gA+UQ/zt+IgWLxyp9kKrPu7gfZhZoEn/oqFIUVY+Ugrj5g8Lf97kLcX6ts3LAFtxql/QbTnbrlWqBbHYzmzfAVyptGxEFltRuDuDUWtRwFge2Oy6qYlnumeeFk+s8nRWrqWxB2IR4DIcdHAzO4zYL4LoGf3W5TlH9Ujk+EOntu95B8BafR7X+K+j/Rgy4Ox3y09iAxixiMbfJ5H1jeZzFH4wJhefgmlORNZ0ax5i8R7HpvTuSy9Maw3VIjzuIV7h7z+kZfRIrFLv/JbdbVnxn1tTtf6YHk9sDYmKf+LW7DRGrvlSO7V3Yz8LqrKt4B2fSmtMJsn1y3UzE3XY+0S4XsgfqFxCzAiGlmtPfkzGnmdW3Jwdx+RY4/Rirxpr4C+vLE3kZft80ZyPRR4swxA/2bc6NlINgB8/f1Y35I/mr5G5e9qA3I2w6nneCr0CK/SEzXKXSpymssaQnDmCUCWTnrra963hx7+liEfsK6ch0jtP3IvQy1afe8ma5d+TSsu1XLXv4Up0O4zgNL44tJcZV3vdZdbhvWUj5Uwss0EvkXtzG7b/lr5zdR09Gt5+buWNV9kWSJwiADLhMs81Qz4PI3HyJj2AtXISxyBaFa3ked71/CRLEyscNEBPA8J3lsy+D382WCIDIsfAKOy/K/Xvb113up7f7+hm4+3Bq4eFui+eT2egRjxqN/8Gre1tDfNFN9ZQXHhcANKKFUGpitcs64w6HvwXkMZgDsrFXvG7tr/Af2yBetveOqnlofvZMsm26ijaD5YUpvLvcrsd5UAgJzRvhQL1wVekGj3gb3l02Sm+MiLzADcx42AMzMkI0A0sDnioY48zJFR2mMgIhA/ArxZfv/n40a8gPEw9bTXQHuQ3nIOON+EXL6oTM/Tr68P+0bi+EE7PA6Aa7lQ9ssc3PCTraxX7TX7uttkdqM/qLkA6xZF74m7hN6LE2DZSzJ17Tw1QLyebTLWrTZkD0wLxXj99f45m8jmRTC7p+Ltq1IdgAN4osuHFupkqAyEuVz7SRJoF4ol7GaH9oCIu7PIEA6o6HluBhT+ASHz8Gm9bY+IB6V/UBmBQZRX0O+bjtIbsUwRz8yI7EkflR2t4Rp5EMuAjz3wqG2YBH1/+LQb4JXm4zCuV7azaTRQWcYpSLOVbxsExu20QY+whEKPhf0blqH35OcvLnG3qmAoxHwNYbTl3WgIGYF6Twgja0Ylsxrp6vJnb1Ku6WyZwhv0la+Bs9aq7dFfnhwwXjCA+1ZUF35y+Y1OWnaaZGdljAZqVukobUZ7AM6HZ3yywbMXJLZojxE4wiszZp620u0p24M0h/v28Qq8Rz7+9WVuHR/wENQPupb84In0wmRNoKjzwOYk/Ui+aBtY5pDgsdbAJblh4G3OQgEhTqAt/oMOlZkE8UooFkBf19hUHjns644Rofv17BJt0nmw107nR2Mg05c9Yc4MdeX0Xn8Qr07/M2Y7ZNqMPALMEbhIknZEW95pRnvA6z60VymOAncEUP6eQSlqY0vPAOXXwDNvwZd51EuxvKO0I8oGQTfb3pF/lC7ynHx9PS8P1hvt8whLKAUNwgPu+QUcak1xLVq9YdermaVfC3BoFmmhUP4VlJmHfXXeQszT7r3wpuR6PXehJpg2MUcczI15SieDIDjfJCiw1oUYT665Q4oGgbV9BhaRwD79kcGelT0q12gEfqP7PbQXAEZyeNppVJt23NsWUZjl589IbbWnB6c5Cc9oZDCjffWZHJ6nT+cHy9H8QPt8Zos80B/QqUfwwM2N9ecqUnT0KSmx/+KdGJQ5jqsNs9d/bakF57WVbTtgBN5+Vrvoa6yBXvLIkfGy+LhRy0TlRWH+Iwn8ynuTN7My3nKNACWqYLbeupf2eESRNYvy7TEC2dLDER53qeOWd52l2/IuBW17mMfhv2RjQ/EJpeclkWho+qWSyOjsNapbBmvL0xnRXmM+ysd64cMzJyBzeJ4rD7wjV8uR2xk2pDOdoVKYV23x3oXcZ/IWPLJXacSF870/SdD+z9zLfna4hSlZfKb/2RjZgz1+PNYm1B1ORmRhbDA7xW2+9EVxoujfPtxTZjbJyRrah0fk446kjWSM8ozSZVO7LRqBuqfQYhPN9Bv5YZFRG5WZlXXAEw3L2WOUIzmyPojyRjOPSIaRh50B+A56BAD3e3kCqZsHm2VUR55LOJpKWPOFZ79Vz7dwxAMuzfJrJwS25wRGZTDHVc6RUxqfadLzjQyzH9N+v3dGkTNqZF/K4ZdgRVHPqocsDzjD03yNlg+GxlPlAChuT8sD0+aQuQjAuaK+IhPa16AzYPY7L1iuCHyjMK6T/1TX1oD0+nwXQI6uj4DnFgnW41WNl31+zE73Y+VjT3yPocm8kPt6HxltAfxWnqxOXi+3Zp+jvAfo8XahGAJ4l2t2+ybUEs9Jg9OoqhuO/QiM525rW6/x7ffm21ClOwNbWxaZGx5zObiq5TDXvNFRsyzRci3luKoMXzyd3bWgPXiNyzqjf8CtaG3njKVbTg5k/QtGnXB7vMsI9BXrpwFL+IRy/lm0fYfsdQPWDDhcVjaFz7wmL3s0eEdgOQKIzCP2pxdGZZ1dnL/29fQPO6I0Rn6Kb237MpXxMlYQ53ax84czIxetgY9oa7ppihy1UwaK0ZTxCHD6tlO0epjl4Wt7JduIfdpoL/BAjx5nDbzxiDxQG6hLTd5c1PRKg1fXJIOXevp+6r9m4x05zuvTRnyjHSZtrKU3I9LLEAF2JP/WPZ+KHjlpDNaps8T20eQRtJ84G3ng0cDaAHKdsH6wSQuAb3nTHO9f6VfQM3Nt8zQyUUWbumi7w8J7gZY3mFGEntmIojp5eUfr7iMgieTakkPcn5FZfwNtnycyZL7dtp4fjGS2fBmPvd51VhaXEckRxe0x3pEe+99MhwLaBeAi8kUA/msA/1wp4o8A+ASAHwLwREus4QAAEedJREFUbgCfAvCNqvqrG5zQ7kzmUSvAHBxerkpIavlrJNqPJG9rppKLYWNvNYCL17yUsu725radnQy9Qc1lWA+QXdNEOqmUOq5D+2t8vE6Zlx1JFGGNut/mpR9KVz/x561ZJFiw1t1cO4W1DUjNIZX8RD8ETwo3gX26GcFB/0oyS8sr8hZnTd6MlNg4RQ1vhsCHZx55RNH+ad9eWxQtPRkf309+WM4u3Pe33/u/BWaRHFF7RnmjE+KOeNTGKwPrqD2jB+0j8Ob+znanRGPE7u8L4AC+F8D/rKq/X0ReAvBPAfhTAH5EVb9bRD4I4IMAvn2bVSKNYAFjDeZwisWF0qA167cxa0BQxqrdy5dvWkiam+Oilt7oH6TzCFnLWPpYmlS2as3r14IF/KWWAccjp6P6aHmMr59VRD3gz0LxjmnDY0I9x7v5FrU149mFWWYe8NbATkFvZTnPzGQ5CaBPgCe3rgw4222sZVlH53pPqpgmxTQLZFqRhR8qy0zrNsWAtI9i5mJcTA8t68kKiY883uMJsuEbAZHdeyPAw2LLh2EPMppNjORm687p9yjwCCS5LP/mZD6Uj3vZW4ZzT549dc5mh55HFj9K62gTwEXkNwL4PQC+GQBU9U0Ab4rI+wB8VUn2AwB+FHsAvPu25d4W1eQ292HZ015gNYrPRknWyu3pJVpgmo+pyh5nSk3bl8F6rC5XLF/so2+B/UhfR2PCgNyc1uqwRoq61cUBcFt4/QpVibMDK6udzgawrj+GZ+s6egk1AJa+/xQKKes2dkwP11lsyqEOZVWpPoz4iGkLXEdr4FG9Pd8tYMv6yIOsHyJ7hkrWryM5RuF76mHX2WzEUz6st8vxPDKD5vOPeKRpMhxqaY8H/h4AfxfAfyMi/wKAjwD4VgBvU9XXS5pfAfC2KLOIfADABwDglVfeuVGUDa4ygoB1YNRGcjWfMq1qRzeDtzRpJ0zlk2Zr3HrY60qrOyDdFgeDZjQA7Uu0b+4sNWtPi+e95XY1epWezUUWnxuFNo2/tvsb9EudAiyTJMMxXj8yBjzBidx6Tsvhupy7MsnqxN+gnMMyWhYgTBWUkw6ntc4nGGbrCrgA5rKnaELB3jKdULGlMhpE9ZydVdalrnSoy3Qag5lfkwOlRRDOcRik8en8EIge5mT5vXxKfxznl0ksfmRctoDdy8UPcUb5R0aLZ4PR8gXLH0NH3x5R+SO8jYyS5xmtVeJcFD8H8T0AfgPgvQD+mKr+uIh8L5blkrV8VRUJD7OFqr4G4DUAePXV366rC2cnD1pCgyztK1y3BLqRagmbd7vN/yIjABDAMi0ayQdRGfTyB86oQNKlOoJXMSuPVU7FupAyYUK/B2WJOQXab559fxqhAo6HfaenPU9lnRn4Q7D8+nZnMLTEawFAWW2nHWxV03qlHDkNPo0pr/E+r1/DqnKZA92BT1zQZIBv6gH7UukMPrFrghbPfm7qsZzBXtq5ylkG0jQvO6XCygvah+gOeawy9Rx8hzqZp9Y0BoVFRm0LRL3IHrQ8UDs71vFkfOF1OC9DdB/xY0OwBfhGEYBn9Rq18djZbdMyGU9v0Ow3eibTleUcUwXqW+vdqsVKewD80wA+rao/Xu7/RywA/lkRebuqvi4ibwfwuR28qGIOwIvcYU80bqK2fEJNaLXQJslUSFOkQR8AzBX4VihkvqsOSBPWPhOK96JI5esB3AC+vTeT035/fpFSqGwLb5+tzFVWpxoNeDdyq7SPeCuIy5oGZQeKRrvWXWHpgHB9SDZZ/F7qtToJTzboph7BKe2iqJ/xs1aTpR4eDaVA+Drbs/jCo9NT1i3fV9QD5oSILpvsowaaKG800KMZD9z9qA9YxGjZgUGUeXgliuK8XBnuMEBnYBiBeKZPGQTQbKuVR4K0Cf9N4EXY1Q3P6KWMrG2Yvxn7AW0CuKr+ioj8soj8VlX9BICvBvBz5e/9AL67/P7wFq/lCdPN8nt+y/L128meTpmbhdbi1MZxrRcp2goxiB71ZltAJ9Lkafj43J8XyFDNoNuvti+/ZwLvdl47Qelhv3H03FpjIw38+s+3zZUH/1rJy99UedgGjfZjwgXwVBbZOs/NHjrvoFBhS2HsjZ6bAtpfJUYMroLW853dRlspLnnzTTegrodX3SIEUs/jvKarHwahylXnwuSb2nr55Zem2Shdtt+dqj6yEU248fNFGfFUh6m1Zz1wkT3bBaoGYDzdS+xXr2NEI1VLgZGY2ENmzzdzDqw7vUyRt2/hvp1sK5iRpeH2jfayA8tU9/R04NXs34XyxwD8YNmB8osA/p0i1p8XkW8B8EsAvnEXpxlYByNWqQWA3AJnt2dJWVssIWhwUE/XKYe938tesg3UqYJO/Ta83K7eUZVtaoqzMpYHYu1+NK3hayXtK/O3XY8uUPq0afrlG/arfi/y3uKEGYpzBezlY8nLQozg7NyDU8NjectCMTXfXT0BuIHgBlqu+mqu/va8eIpnQXtIyrz0ixZPsu7eKHWdqc4MutYtCiyf7yn9qoQkda2GAbqU48mAUNHGd54pOQanIJ0BsvEQLIDPB3jbIFLjx3pocvDoLtdm4NT0r+jlRINST6tx8PrfyFn+bl24FRddb3npkWH1QBKlEbTryx7AePjZtQdwP6zV/UU7hDuFLVRBUtF+dzeoXFf3osPZMZv8rkqzM0bb9uQn5xbWLP9SWRw0AfVgfRsvosD0dHFw7wvgqvpRAK8GUV+9J//KCOgOqjJPqnpBk2s/A9XiDYoNiNIQk2tEwfo2Z+0Q0gT6iITY/1XxZGWiHL7KseYxmLPlmXhNmoHdNiyuvt2aY4LWtOv1VMbImnrCXL54P2Em3vYJiVW/bUFSwOv5Vv6puVtr0pCW9d5z6YPK/FzAGwtYWx/WzeHOs/beHI9SpfxN2U4vmq0opTW0lM+DAlj6RgTdcptOZgUpLaXhvrYlF7H5z7wESym7aVGgPUfeeDn3rQ5Qn6yNa/rB72xhv8XrfdCMIXmgjWgPiKv7DYZbk7+dIgZ6gdaz99tRPY9GJzks2n+I4hzMbVqgxRQv8xaNDGTtL1Iu/h5vY+DKLJFfgJhuF0M/eIJ/2TcxJwVeMk/jTdQBDFDHnctgdaKdb8oALKNPZQl78nRZilkCSyeVtNZCcgbkFs2U1njoBDyhwW5g0FhktEDzZPXA7GX39VX65V7Kg8mVgwJ4Wl+CeaPsfJEatwKfQcZN8bHX7puhuC3gLXjaNJAUx8yMgGDChBugzAaW8NvS0Ev8Ge0DUm3XUFQXgDxLCxi2l3p2xnZWakegerZWtdsasYLIjGVQ1ajTusnceBjv5gtOWBT7bDs/aDRMAG7oicAEakWvF4ipWbIjoyROL/wySzNAWdbibLBzUOi2GM8JgJwVrTFqq9a0G5O6Pw7nNVgDwFu0xODr8wM9Unjw5rz8BllUBhsiD+Lmd9ir+kbma/DZEBNWfa3yKHCr62yKVxlniV8WBPrvCUpwbbJNiNvrnORhxvyhWaMbLLo83VIbzcDLb6wz4IQu/Cq9rNbu9LR41WSZZkG3IGThdXrLA9FbNes08tibPAWopWjvXB5UaaC1UrSwGsRiuXUCa5f52EKaqA3kSkmnFUaXlfA3qs+7gPpc163NBKD8rnq/LJzYIoqNQnZM1h0vS6qbYloMwG9gnW5tfEttKMWjZa+0jEheojiX/HUw8C4O8opslNZB6drYDCUD+FR0YnJpzyjpSA7rNoFbkpiKMaH8wArKDWgUnWxeEtN+kFl72VKIeczNC0DRNgx2tUsZ9ROApcqlj0VlqUetevCg32+jtTrMknvg3hbxr5GJbettkYHwJC6cAZjjzNv2APc0KMefrzIqn9PN1M6GFx73LC7i1XRdYkC57RqnQXPjOXO6II0ZsbrVyjBnAs4vA7dTvKxW6BEAvKx3yhvFqypRKljWAguAC4XPN6VDilYIsAyE4ImPSAEB9g6t1SbUh1nAOhi7Y+RAACIlHU9vuFzb7aG1pOX3TPfLMstU1saXXKsLtADwsobd1KVe8TLHsnd5wZcz5W8dg+qgFM/OOJ+gDYA374qqAThRNXCytkVd64ufEyxhDLSWr/SdnWMzkxtWm5anuJTWwL965CieiRll8qbrNj3jqWs+3pkwY9GTCWgP9WjrIvT/qktCdSPHQVa9WIj2+3dGYbldF/TMOHDxDkGa77kaX/I4OVsE1tm1ARjbMbi0kSMYgZtPb2G3jgc/nDF5s4ejXO0onI1ZnTHq2kzcLRmAR+0VzSQ62aRv19qWpqNZXle2zfBUgfNLy6aP2yeBwCW5bmxTeUgSkb8L4P8F8PcuVuh+eiuuch2hq1zH6CrXMbrK1dJvVtUv9YEXBXAAEJGfVNXogeij0lWuY3SV6xhd5TpGV7n20c5NvFe60pWudKXnja4AfqUrXelKLyg9BoC/9ghl7qGrXMfoKtcxusp1jK5y7aCLr4Ff6UpXutKVHoauSyhXutKVrvSC0sUAXES+RkQ+ISKfLF/weRQSkXeJyP8qIj8nIj8rIt9awr9LRD4jIh8tf1/3CLJ9SkQ+Vsr/yRL2xSLy10TkF8rvb7qwTL+V2uSjIvJrIvJtj9FeIvL9IvI5EfkZCgvbRxb6L4q+/S0Ree+F5fpPRORvl7L/cvksIUTk3SLy69Ruf/bCcqX9JiLfUdrrEyLyr11Yrh8imT4lIh8t4ZdsrwwbHl3HUlLVZ/6H5V2FvwPgywC8BOCnAfy2S5QdyPJ2AO8t118I4OcB/DYA3wXgTzyGTCTbpwC81YX9xwA+WK4/COB7HlG+E5aPd/zmx2gvLF+Gei+An9lqHwBfB+B/wvIKxe8A8OMXlutfBXBTrr+H5Ho3p3uE9gr7rYyBn8byzfn3lPF6upRcLv4/BfAfPEJ7Zdjw6DqW/V3KA/9KAJ9U1V/U5ZNsHwLwvguV3ZCqvq6qP1Wu/yGAjwN4x2PIspPeh+WTdSi/v/cRZflqAH9HVX/pMQpX1f8NwP/tgrP2eR+AP6cL/RiALyrn1l9ELlX9q6pqr9v+GICtz1FdRK4BvQ/Ah1T1DVX9vwB8Esu4vahcIiJYTjb9H55F2SMaYMOj61hGlwLwdwD4Zbr/NJ4D0BSRdwP4CgD2sYo/WqZC33/ppYpCCuCvishHZPkUHbDz03UXom9CO7Aeu72AvH2eJ537I1g8NaP3iMjfFJG/ISK/+xHkifrteWmv3w3gs6r6CxR28fZy2PDc6tg/sQ8xReQLAPxFAN+mqr8G4M8A+C0AfjuA17FM4y5Nv0tV3wvgawH8eyLyezhSl3nbo2wbkuUs+G8A8BdK0PPQXg09ZvtkJCLfieUUkB8sQa8DeEVVvwLAHwfw34vIb7igSM9dvzn6A2idhIu3V4ANlZ43HbsUgH8GwLvo/p0l7FFIRJ5g6aAfVNW/BACq+llVPavqDOC/wjOaPo5IVT9Tfj8H4C8XGT5r0zI58um6h6evBfBTqvrZIuOjt1ehrH0eXedE5JsBfD2AP1QGPsoSxd8v1x/Bstb8z15KpkG/PQ/tdQPg3wLwQxZ26faKsAHPsY5dCsB/AsCXi8h7iif3TQA+fKGyGyprbN8H4OOq+qcpnNeu/k0AP+PzPmO5Pl9EvtCusTwE+xks7fT+kuz92PPpumdDjWf02O1FlLXPhwH822WnwO8A8P/QNPiZk4h8DYA/CeAbVPUfUfiXiiwHhYvIlwH4cixfubqUXFm/fRjAN4nIyyLyniLX/3kpuQr9ywD+tqp+2gIu2V4ZNuA51TEAl9mFQk9sfx6LBf3OSz+tJTl+F5Yp0N8C8NHy93UA/jsAHyvhHwbw9gvL9WVYdgH8NICftTYC8CUAfgTALwD46wC++BHa7PMB/H0Av5HCLt5eWAzI61hOkv40gG/J2gfLzoD/sujbxwC8emG5PollfdR07M+WtL+v9O9HAfwUgH/jwnKl/QbgO0t7fQLA115SrhL+3wL4d13aS7ZXhg2PrmPZ3/VNzCtd6UpXekHpn9iHmFe60pWu9KLTFcCvdKUrXekFpSuAX+lKV7rSC0pXAL/Sla50pReUrgB+pStd6UovKF0B/EpXutKVXlC6AviVrnSlK72gdAXwK13pSld6Qen/A6Q11GAC5+mQAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI_XXZQCGLSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "N_img_height = 66\n",
        "N_img_width = 220\n",
        "N_img_channels = 3\n",
        "\n",
        "def nvidia_model():\n",
        "    inputShape = (N_img_height, N_img_width, N_img_channels)\n",
        "\n",
        "    model = Sequential()\n",
        "    # normalization    \n",
        "    # perform custom normalization before lambda layer in network\n",
        "    model.add(Lambda(lambda x: x/ 127.5 - 1, input_shape = inputShape))\n",
        "\n",
        "    model.add(Convolution2D(24, (5, 5), \n",
        "                            strides=(2,2), \n",
        "                            padding = 'valid',\n",
        "                            kernel_initializer = 'he_normal',\n",
        "                            name = 'conv1'))\n",
        "    \n",
        "    \n",
        "    model.add(ELU())    \n",
        "    model.add(Convolution2D(36, (5, 5), \n",
        "                            strides=(2,2), \n",
        "                            padding = 'valid',\n",
        "                            kernel_initializer = 'he_normal',\n",
        "                            name = 'conv2'))\n",
        "    \n",
        "    model.add(ELU())    \n",
        "    model.add(Convolution2D(48, (5, 5), \n",
        "                            strides=(2,2), \n",
        "                            padding = 'valid',\n",
        "                            kernel_initializer = 'he_normal',\n",
        "                            name = 'conv3'))\n",
        "    model.add(ELU())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Convolution2D(64, (3, 3), \n",
        "                            strides = (1,1), \n",
        "                            padding = 'valid',\n",
        "                            kernel_initializer = 'he_normal',\n",
        "                            name = 'conv4'))\n",
        "    \n",
        "    model.add(ELU())              \n",
        "    model.add(Convolution2D(64, (3, 3), \n",
        "                            strides= (1,1), \n",
        "                            padding = 'valid',\n",
        "                            kernel_initializer = 'he_normal',\n",
        "                            name = 'conv5'))\n",
        "              \n",
        "              \n",
        "    model.add(Flatten(name = 'flatten'))\n",
        "    model.add(ELU())\n",
        "    model.add(Dense(100, kernel_initializer = 'he_normal', name = 'fc1'))\n",
        "    model.add(ELU())\n",
        "    model.add(Dense(50, kernel_initializer = 'he_normal', name = 'fc2'))\n",
        "    model.add(ELU())\n",
        "    model.add(Dense(10, kernel_initializer = 'he_normal', name = 'fc3'))\n",
        "    model.add(ELU())\n",
        "    \n",
        "    # do not put activation at the end because we want to exact output, not a class identifier\n",
        "    model.add(Dense(1, name = 'output', kernel_initializer = 'he_normal'))\n",
        "    \n",
        "    adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0)\n",
        "    model.compile(optimizer = adam, loss = 'mse')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rGxcJ99GMyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.core import Activation, Dropout, Flatten, Dense, Lambda\n",
        "from keras.layers import ELU\n",
        "from keras.optimizers import Adam\n",
        "val_size = len(val_data.index)\n",
        "valid_generator = generate_validation_data(val_data, model)\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', \n",
        "                              patience=1, \n",
        "                              verbose=1, \n",
        "                              min_delta = 0.23,\n",
        "                              mode='min',)\n",
        "\n",
        "modelCheckpoint = ModelCheckpoint(drive_location+ \"/speedchallenge/weights.h5\", \n",
        "                                  monitor = 'val_loss', \n",
        "                                  save_best_only = True, \n",
        "                                  mode = 'min', \n",
        "                                  verbose = 1,\n",
        "                                 save_weights_only = True)\n",
        "\n",
        "# tensorboard = TensorBoard(log_dir=tensorboard_loc, histogram_freq=0,\n",
        "#                             write_graph=True, write_images=True)\n",
        "\n",
        "callbacks_list = [earlyStopping, modelCheckpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSajsmzjdg0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = nvidia_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRRTisTEdjXf",
        "colab_type": "code",
        "outputId": "8a37e997-718d-4268-c8df-81f85adb8c48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "num_epochs = 25 #100 #90 \n",
        "steps_per_epoch = 2\n",
        "train_size = len(train_data.index)\n",
        "train_generator = generate_training_data(train_data, model, 16)\n",
        "history = model1.fit_generator(\n",
        "        train_generator, \n",
        "        steps_per_epoch = steps_per_epoch, \n",
        "        epochs = num_epochs,\n",
        "        callbacks = callbacks_list,\n",
        "        verbose = 1,\n",
        "        validation_data = valid_generator,\n",
        "        validation_steps = val_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1/2 [==============>...............] - ETA: 8s - loss: 6.2143"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-501fea9a995b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         validation_steps = val_size)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    240\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                             workers=0)\n\u001b[0m\u001b[1;32m    243\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                         \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1789\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1791\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 raise ValueError('Output of generator should be a tuple '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV0ZW8vwtV3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/drive/My\\ Drive/comma_ai_speedchallenge/speedchallenge /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byYD4QYfNExV",
        "colab_type": "code",
        "outputId": "0a6ba10d-191b-4ee9-f885-a1780d5d5e85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model1.predict(torch.tensor(to_save).unsqueeze(0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[21.310968]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU6VTYKUNzdJ",
        "colab_type": "code",
        "outputId": "7964bee3-bfe7-40a3-8488-415e73fb2e9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "val_data.iloc(0)[13]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "index                                              503\n",
              "image_path     speedchallenge/data/trainFrames/503.jpg\n",
              "image_index                                        503\n",
              "speed                                          16.5201\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjParPLeOv94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.save(drive_location+\"/speedchallenge/data/model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J8jNWDlP-UR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYl7BnEyQd5M",
        "colab_type": "code",
        "outputId": "516aa8f1-1ffc-4d05-d10d-aa2c883765f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[21.310968]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    }
  ]
}